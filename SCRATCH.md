# SCRATCH.md

Executive summary (prioritised) 1. Make spreadsheets an ingest format only; enforce schemas and quality gates. Declare schemas in machine-readable form (Frictionless Table Schema) and validate every file; attach CSVW sidecar metadata when you must ship CSVs. Gate merges with Great Expectations suites. ￼ 2. Adopt a canonical “Party / Role / Alias” model to represent people, organisations, and branches; store all AKA/TA handles as first-class alias records with provenance + validity windows. Use UUIDv7/ULIDs for sortable IDs. ￼ 3. Resolve entities probabilistically with a human-in-the-loop. Use Splink for fast, scalable record linkage; RapidFuzz for string similarity; nameparser, phonenumbers, and python-stdnum for deterministic normalisation; route low-confidence merges to an annotator (Label Studio). ￼ 4. Keep it performant without bloat. Use Polars + DuckDB + Arrow for analytics; store validated tables as Parquet; keep pandas to the margins. Package with Astral uv, lint/format with Ruff, and keep YAGNI/DRY sacred. ￼ 5. Instrument, secure, and prove compliance. Add OpenTelemetry traces around every pipeline step; enable GitHub Advanced Security (code/secret scanning, dependency review); scan licences with ScanCode; adopt REUSE metadata; respect robots.txt and ToS; add PII detection/redaction for inbound text. ￼ 6. Orchestrate with agents—but with guardrails. If you bring in MCP-enabled agents (Copilot/Codex-style), use the Model Context Protocol and the GitHub MCP Registry; run tasks via Prefect with role-based approvals and policy checks. ￼

⸻

What I reviewed (repo reality check)

I inspected the Hotpass repo structure and README (docs/, data/, src/, policy/, tests/, Prefect flows, Great Expectations, OTel, Streamlit); the tree suggests a data pipeline with quality checks, orchestration, and a simple UI already present. Treat the following as targeted hardening + refactor plan on top of that base. ￼

⸻

A. Spreadsheets → canonical data (consolidation & formatting)

What to change
• Declare schemas per table using Frictionless Table Schema (schema.json) and ship CSVW sidecars (your.csv-metadata.json) for any CSV published/consumed. That gives types, constraints, foreign-keys, and column semantics in JSON and lets you validate in CI. ￼
• Validate every ingest with Great Expectations. Create one Expectation Suite per table (nullability, allowed sets, regex shapes, PK uniqueness, FK integrity, date windows). Fail the run on contract violations. ￼
• Normalise formats at source:
• Dates → ISO-8601 (YYYY-MM-DD);
• Phones → E.164 (using phonenumbers);
• Standard numbers (VAT/IBAN/etc.) → python-stdnum validators;
• Names → parsed with nameparser, stored as components plus a raw form. ￼
• Persist post-validation in columnar storage (Parquet/Arrow) and query via DuckDB; use Polars in transformation steps for speed and memory efficiency. ￼

Why this matters: you stop schema drift and “CSV roulette,” and you get reproducible, typed datasets that are fast to query and easy to lint.

⸻

B. Multi-person / multi-branch entities + AKA/TA handles (data model)

Core pattern: Party / Role / Alias (lean, DRY)
• entity (party): entity_id (UUIDv7/ULID), kind ∈ {person, organisation, branch}, parent_id (for branches), lifecycle fields. ￼
• role: entity_id ↔ org_id, role_type, start_date, end_date.
• alias: entity_id, alias_type ∈ {legal_name, trading_as, aka, handle, ta_handle, former_name, transliteration}, value, context (e.g., platform for handles), locale, source, confidence, valid_from/through.
• contact_method: normalised phone/email/url with validation status. ￼

Threat-actor handles / AKA hygiene
The threat-intel world lives with alias chaos; model it explicitly. Keep many-to-one alias maps and provenance per alias; don’t over-merge across weak evidence. MITRE ATT&CK and MISP both expose that groups accumulate many names; mirror that reality in your schema and UI. ￼

Spreadsheet guidance
Supply a single “Hotpass Data Dictionary” sheet autogenerated from the schema (column, type, description, required?, constraints). If a contributor uploads a sheet lacking required columns or with illegal values, the Great Expectations gate fails with a human-readable error report. ￼

⸻

C. Entity resolution (dedupe/linkage) without bloat

Stack (small, sharp, battle-tested)
• Splink for probabilistic matching at scale (blocking, m-u probabilities, clerical review thresholds). Use deterministic pre-rules (exact emails/IDs) before fuzzy. ￼
• RapidFuzz for fast string metrics (token sort/ratio, Jaro-Winkler) in your comparators. ￼
• nameparser / phonenumbers / python-stdnum for canonicalisation before scoring. ￼
• Human-in-the-loop: pipe uncertain pairs (e.g., 0.85–0.92) to Label Studio for adjudication; store labels for incremental retraining. ￼

Why Splink? It’s open-source, well-documented, and fast for big joins; government teams use it for cross-system linkage. ￼

⸻

D. Performance & toolchain (frontier-grade without bloat)
• In-process analytics: DuckDB queries over Parquet; Polars for transforms; Arrow as the common columnar format. You get orders-of-magnitude speedups vs. spreadsheet-centric code, with minimal moving parts. ￼
• Packaging: adopt uv (fast resolver/venv/build) and keep lockfiles; stick Ruff for lint/format; protect main with pre-commit hooks. ￼
• Observability: insert OpenTelemetry spans around each stage (ingest → validate → canonicalise → link → publish) to get timings and failure breadcrumbs. ￼
• Orchestration: the repo already mentions Prefect; keep it. Flows stay pythonic; retries and caching come “for free.” ￼

⸻

E. IP/compliance & “never-flagged” aspiration (realistic guardrails)

Reality check: zero-flag risk is not physically attainable (false positives exist), but you can minimise it and produce an audit trail that clears you fast.
• Code & dependency risk: turn on GitHub Advanced Security (code scanning/secret scanning/dependency review). ￼
• Licensing: scan inbound/outbound code/data with ScanCode; record licence findings; adopt REUSE so every file declares copyright/licence machine-readably. ￼
• Data acquisition ethics: honour robots.txt (REP RFC 9309), but know it’s not access control; prefer licensed APIs or explicit terms. Maintain an allow-list of sources + ToS snapshots; block “grey” sources. ￼
• PII control: scan free-text with Microsoft Presidio; mask/redact before storage; log detections with category + confidence. ￼
• Provenance ledger: for every row, store (source, fetched_at, licence, rep_policy, hash). This is your white-label insurance.
• Telemetry & audit: OTel traces + immutable logs (append-only) make incident response and DSAR-style requests tractable. ￼

⸻

F. Agentic workflow with MCP (optional, gated)

If you want agents (Copilot/Codex-style) to orchestrate parts of the pipeline, use Model Context Protocol so tools are discoverable, permissioned, and observable:
• MCP clients (the agents) connect to MCP servers (GitHub, Drive, Playwright, internal data). Use the GitHub MCP Registry to standardise discovery. Gate every agent action behind Prefect tasks and human approvals at risk boundaries (e.g., merge decisions). ￼

⸻

G. Concrete, minimal-bloat changes (rank-ordered) 1. Add schemas + CSVW: create schemas/ with Table Schema JSON; emit \*-metadata.json next to every CSV; wire validation in CI. ￼ 2. Expectation Suites: generate baseline Great Expectations suites per table; fail CI on violation; publish validation docs as build artefacts. ￼ 3. Canonical model: introduce entity, role, alias, contact_method tables; back-fill from spreadsheets with migration scripts; IDs = UUIDv7. ￼ 4. Linkage: add Splink project with deterministic pre-rules + probabilistic comparators (RapidFuzz); wire a clerical review UI via Label Studio for 50/50 pairs. ￼ 5. Storage/perf: convert validated sheets → Parquet; query with DuckDB; refactor hotspots to Polars. ￼ 6. Governance: enable GH Advanced Security; add ScanCode + REUSE checks; wire Presidio scanning for free-text fields; embed REP/robots/ToS checks into any web fetcher. ￼ 7. Observability: instrument flows with OpenTelemetry and surface a Prefect/Streamlit “Runbook View” (what ran, durations, failures). ￼

⸻

H. Sample “Party / Role / Alias” schema (drop-in)

{
"entity": {
"id_type": "uuidv7",
"columns": [
{"name": "entity_id", "type": "string", "constraints": {"pattern": "^[0-9a-fA-F-]{36}$", "required": true}},
{"name": "kind", "type": "string", "constraints": {"enum": ["person","organisation","branch"], "required": true}},
{"name": "parent_id", "type": "string"},
{"name": "created_at", "type": "datetime"},
{"name": "ended_at", "type": "datetime"}
]
},
"role": {
"columns": [
{"name": "entity_id", "type": "string", "constraints": {"required": true}},
{"name": "org_id", "type": "string", "constraints": {"required": true}},
{"name": "role_type", "type": "string"},
{"name": "start_date", "type": "date"},
{"name": "end_date", "type": "date"}
]
},
"alias": {
"columns": [
{"name": "entity_id", "type": "string", "constraints": {"required": true}},
{"name": "alias_type", "type": "string",
"constraints": {"enum": ["legal_name","trading_as","aka","handle","ta_handle","former_name","transliteration"], "required": true}},
{"name": "value", "type": "string", "constraints": {"required": true}},
{"name": "context", "type": "string"},
{"name": "locale", "type": "string"},
{"name": "source", "type": "string"},
{"name": "confidence", "type": "number"},
{"name": "valid_from", "type": "date"},
{"name": "valid_through", "type": "date"}
],
"uniques": [["entity_id","alias_type","value","context"]]
}
}

Pair this with an Expectation Suite that asserts uniqueness, non-nulls, and allowed enumerations. ￼

⸻

I. Evidence-gated protocol (for the big calls)

1. Adopt Splink-based probabilistic linkage (with clerical review)

Data: Large, messy entity spreadsheets; alias chaos.
Methods: Probabilistic linkage (m-u model) with Splink + deterministic pre-rules; RapidFuzz comparators; adjudication of uncertain pairs via Label Studio; store decisions for re-use.
Key results: Superior scalability and speed vs naive/deterministic linkage; government-grade adoption; reduces false merges by deferring to review. ￼
Uncertainty: Threshold tuning is dataset-specific; bias possible if training pairs are unbalanced.
Safer alternative: Deterministic linkage only on high-precision keys (emails/IDs) and manual merge queues (lower recall). ￼

2. Make CSVs contract-aware with Frictionless + CSVW + Great Expectations

Data: Diverse contributor spreadsheets.
Methods: JSON Table Schemas, CSVW metadata sidecars, Expectation Suites in CI.
Key results: Automatic rejection of bad files; explanatory error reports; documented contracts; fewer regressions. ￼
Uncertainty: Contributors must adopt templates; initial friction.
Safer alternative: Read-only OpenRefine pass with manual checks (slower, less consistent). ￼

3. Compliance stack (GHAS + ScanCode + REUSE + Presidio + REP/ToS)

Data: Source code, third-party artefacts, scraped text.
Methods: GH Advanced Security, licence scans, machine-readable licence metadata, PII detection/redaction, robots.txt honouring.
Key results: Reduced secret/dep vulns; licences documented; lower legal exposure; auditable provenance. ￼
Uncertainty: Robots.txt is not enforcement; some bots ignore it; scanners have false negatives. ￼
Safer alternative: Consume only licensed APIs and datasets with explicit terms.

⸻

J. Micro-PRs you can open immediately
• Add schemas/ + CSVW sidecars; wire Frictionless + GX validation in CI. ￼
• New core/ids.py: UUIDv7 generator + validators; migrate keys. ￼
• etl/normalize.py: name/phone/stdnum canonicalisers. ￼
• linkage/ module: Splink settings + RapidFuzz comparators + thresholds; clerical review hooks to Label Studio. ￼
• storage/: write Parquet; DuckDB SQL views; Polars transforms. ￼
• security/: enable GHAS; add ScanCode+REUSE job; Presidio CLI for text fields; REP/ToS checker for any crawler. ￼
• observability/: OTel instrumentation + exporter and a Prefect runbook dashboard. ￼

⸻

Notes on style constraints (DRY & YAGNI)
• Prefer few, sharp dependencies over frameworks; pick Splink or Dedupe, not both.
• Keep Streamlit minimal—only for reviewing failures / clerical queues. ￼
• YAGNI: no graph database unless relational modelling becomes painful; start with adjacency + closure tables. ￼

⸻

Optional: MCP-driven “smart operator” mode

If you enable agentic orchestration later, register a curated set of MCP servers (GitHub, Drive, Browser/Playwright). Agents request tasks through Prefect, and every destructive action requires an approval step. This keeps intelligence high and blast-radius low. ￼

⸻

Where this lands Hotpass
• White-label by construction (no vendor lock-in artefacts in outputs; provenance carried along).
• Frontier-grade linkage, but still small, auditable, and fast.
• Compliance posture that is demonstrably careful rather than hopeful.

If helpful, I can turn this into a set of GitHub issues mapped to milestones (schema, validation, linkage, governance) and draft the baseline Table Schemas + GX suites to unblock the first PR.
